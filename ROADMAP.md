# üó∫Ô∏è Roadmap de Estudos em IA Generativa

Este roadmap foi projetado para guiar iniciantes no campo da Intelig√™ncia Artificial Generativa, come√ßando pelos conceitos fundamentais e progredindo para t√≥picos mais avan√ßados. A estrutura √© modular, permitindo um aprendizado passo a passo.

Use as caixas de sele√ß√£o para marcar os t√≥picos que voc√™ j√° concluiu.

---

## M√≥dulo 1: Fundamentos (A Base para Desenvolvedores)

- [ ] **O que √© Intelig√™ncia Artificial (IA)?**
  - [ ] Entender a diferen√ßa entre IA, Machine Learning (ML) e Deep Learning (DL).
- [ ] **Principais Paradigmas de Machine Learning**
  - [ ] Aprendizado Supervisionado (ex: Classifica√ß√£o, Regress√£o).
  - [ ] Aprendizado N√£o Supervisionado (ex: Clusteriza√ß√£o).
  - [ ] Aprendizado por Refor√ßo.
- [ ] **Deep Learning B√°sico**
  - [ ] O que s√£o Redes Neurais? (Neur√¥nios, Camadas, Fun√ß√µes de Ativa√ß√£o).
  - [ ] Intui√ß√£o sobre como as redes neurais aprendem (Backpropagation e Gradiente Descendente).

## M√≥dulo 2: Introdu√ß√£o √† IA Generativa

- [ ] **O que s√£o Modelos Generativos?**
  - [ ] Diferen√ßa entre modelos Generativos e Discriminativos.
  - [ ] Breve hist√≥ria: de VAEs e GANs aos Transformers.
- [ ] **Large Language Models (LLMs)**
  - [ ] O que √© um LLM e como ele funciona em alto n√≠vel?
  - [ ] Conceitos chave: Tokens, Vocabul√°rio e Janela de Contexto.

## M√≥dulo 3: Arquiteturas e Conceitos Essenciais

- [ ] **A Arquitetura Transformer**
  - [ ] Entender o mecanismo de *Self-Attention* (Aten√ß√£o).
  - [ ] Papel dos Encoders e Decoders.
  - [ ] Como a arquitetura Transformer revolucionou o processamento de linguagem natural.
- [ ] **Modelos de Difus√£o (Para Imagens)**
  - [ ] Intui√ß√£o sobre como modelos como DALL-E 2/3 e Stable Diffusion geram imagens.
- [ ] **Embeddings**
  - [ ] O que s√£o *Word Embeddings* e por que s√£o importantes?

## M√≥dulo 4: Ferramentas e Ecossistema Pr√°tico

- [ ] **Hugging Face**
  - [ ] Explorar o [Hugging Face Hub](https://huggingface.co/models) (Modelos, Datasets).
  - [ ] Usar a biblioteca `transformers` para carregar um modelo e um tokenizador pr√©-treinado.
- [ ] **APIs de Modelos como Servi√ßo**
  - [ ] Fazer a primeira chamada para a API da OpenAI, Google (Gemini), Anthropic (Claude), etc.
  - [ ] Entender o uso dos SDKs oficiais (ex: `openai-python`).
- [ ] **Executando Modelos Localmente**
  - [ ] Experimentar ferramentas como Ollama ou LM Studio para rodar LLMs no seu pr√≥prio computador.

## M√≥dulo 5: Construindo Aplica√ß√µes com LLMs

- [ ] **Engenharia de Prompt**
  - [ ] T√©cnicas b√°sicas: Instru√ß√µes claras, *Zero-shot*, *One-shot* e *Few-shot prompting*.
  - [ ] Entender o conceito de *Chain-of-Thought*.
- [ ] **Retrieval-Augmented Generation (RAG)**
  - [ ] O que √© RAG e por que √© essencial para evitar alucina√ß√µes e usar dados privados.
  - [ ] Introdu√ß√£o a *Vector Databases* (ex: ChromaDB, FAISS).
  - [ ] Construir um pipeline de RAG simples: `Load -> Split -> Embed -> Store -> Retrieve -> Generate`.
- [ ] **Function Calling & Tools**
  - [ ] Entender como um LLM pode decidir chamar uma fun√ß√£o externa (API, banco de dados, etc.).
  - [ ] Implementar uma chamada de fun√ß√£o usando a API da OpenAI ou similar.
- [ ] **Frameworks de Orquestra√ß√£o**
  - [ ] Primeiros passos com LangChain ou LlamaIndex para construir uma aplica√ß√£o simples.

## M√≥dulo 6: T√≥picos Avan√ßados e Produ√ß√£o

- [ ] **Fine-Tuning (Ajuste Fino)**
  - [ ] Diferen√ßa entre *Full Fine-Tuning* e *Parameter-Efficient Fine-Tuning* (PEFT), como LoRA.
- [ ] **Constru√ß√£o de Agentes de IA Personalizados**
  - [ ] O que s√£o agentes e como eles usam LLMs para raciocinar (ciclo `ReAct`: Reason + Act).
  - [ ] Construir um agente simples que pode usar m√∫ltiplas ferramentas (ex: uma calculadora e um buscador web).
- [ ] **√âtica e Seguran√ßa em IA**
  - [ ] Estudar sobre vieses, alucina√ß√µes, privacidade e uso respons√°vel da tecnologia.
  - [ ] T√©cnicas de *Prompt Injection* e como se defender.
- [ ] **Avalia√ß√£o e Observabilidade (LLM-Ops)**
  - [ ] Como avaliar a qualidade das respostas de um LLM? (ex: RAGAS, TruLens).
  - [ ] Entender a import√¢ncia de monitorar custos, lat√™ncia e performance em produ√ß√£o.